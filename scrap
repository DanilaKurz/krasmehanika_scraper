import itertools
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re

products_df = pd.DataFrame(
    columns=['link', 'Name', 'Description', 'Characteristics', 'Price', 'Quantity', 'Article', 'KP link',
             'Youtube_link'])


def convert_table_to_text(data):
    
    df = pd.DataFrame(data)
    text = df.to_string(index=False)
    
    return text

def table_to_text(soupecky):
    # Преобразуем HTML-таблицу в объект BeautifulSoup

    # Находим все строки таблицы
    rows = soupecky.find_all('tr')

    # Извлекаем заголовки таблицы
    headers = [header.text.strip() for header in rows[0].find_all('td')]

    # Извлекаем данные таблицы
    data = []
    for row in rows[1:]:
        values = [value.text.strip() for value in row.find_all('td')]
        data.append(values)

    # Создаем датафрейм
    df = pd.DataFrame(data, columns=headers)

    # Преобразуем датафрейм в текст
    text = df.to_string(index=False)

    return text

# Использование функции
data = {
    'Диаметр сопла (дюймы)': [0.013, 0.015, 0.017, 0.019, 0.021, 0.023, 0.025, 0.027, 0.029, 0.031, 0.033, 0.035, 0.039, 0.043, 0.055],
    'Производительность вода 138 бар (л/мин)': [0.69, 0.91, 1.17, 1.47, 1.79, 2.15, 2.54, 2.96, 3.42, 3.90, 4.42, 4.98, 6.18, 7.51, 12.29],
    'Ширина факела 5 см': [213, 215, 217, 219, None, None, None, None, None, None, None, None, None, None, None],
    'Ширина факела 10 см': [None, 315, 317, 319, 321, 323, 325, 327, 329, 331, 333, 335, 339, 343, 355],
    'Ширина факела 15 см': [None, None, 417, 419, 421, 423, 425, 427, 429, 431, None, 435, 439, 443, None],
    'Ширина факела 30 см': [None, None, None, None, 621, 623, 625, 627, 629, 631, None, 635, 639, 643, None]
}


def extract_and_format_text(soupca_bi):
    contents = []
    if soupca_bi:
        for element in soupca_bi:
            if element.name == 'h1':
                contents.append(f"*{element.get_text(strip=True)}*")
            elif element.name == 'h2':
                contents.append(f"**{element.get_text(strip=True)}**")
            elif element.name == 'h3':
                contents.append(f"***{element.get_text(strip=True)}***")
            elif element.name == 'h4':
                contents.append(f"****{element.get_text(strip=True)}****")
            elif element.name == 'h5':
                contents.append(f"*****{element.get_text(strip=True)}*****")
            elif element.name == 'h6':
                contents.append(f"******{element.get_text(strip=True)}******")
            elif element.name == 'p':
                contents.append(f"{element.get_text(strip=True)}")
            elif element.name == 'ul':
                for li in element.find_all('li'):
                    contents.append(f"*{li.get_text(strip=True)}")
            elif element == soupca_bi.find('table', {'border': '1', 'cellspacing': '0', 'cellpadding': '0'}):
                contents.append(convert_table_to_text(data))
            elif element == soupca_bi.find('table', {'cellpadding': '0'}):
                contents.append(table_to_text(soupca_bi))
            elif isinstance(element, str):
                contents.append(element.strip())
            elif element.name == 'br':
                contents.append("")
        clean_text = '\n'.join(line for line, _ in itertools.groupby(contents))
    else:
        clean_text = 'No info'
    return clean_text


# функция для извлечения характеристик
def extract_characteristics(soupchik):
    table = soupchik.find('table', class_='props_list')

    characteristics = []
    if table:
        for row in table.find_all('tr', itemprop='additionalProperty'):
            char_name = row.find('td', class_='char_name').find('span', itemprop='name').get_text(strip=True)
            char_value = row.find('td', class_='char_value').find('span', itemprop='value').get_text(strip=True)
            characteristics.append(f"{char_name}: {char_value}")

        characteristics_strings = "\n".join(characteristics)
    else:
        characteristics_strings = 'No info'

    return characteristics_strings


from bs4 import BeautifulSoup


def extract_price(soupcheg):
    price_element = soupcheg.find('div', class_='price', attrs={'data-value': True})

    if price_element:
        price_value = price_element['data-value']
        currency_element = price_element.find('span', class_='price_currency')
        measure_element = price_element.find('span', class_='price_measure')

        currency = currency_element.get_text(strip=True) if currency_element else ""
        measure = measure_element.get_text(strip=True) if measure_element else ""

        price_string = f"{price_value} {currency} {measure}".strip()
    else:
        price_string = 'No info'

    return price_string


def extract_availability(soupecky):
    availability_element = soupecky.find('div', class_='item-stock')

    if availability_element:
        value_element = availability_element.find('span', class_='value')
        if value_element:
            value_text = value_element.get_text(strip=True)
    else:
        value_text = 'No info'

    return value_text


def extract_youtube_link(tochka):
     youtube_link_element = tochka.find('div', class_='video_block')

     # Пытаемся найти iframe в элементе video_block
     iframe_element = youtube_link_element.find('iframe') if youtube_link_element else None

     if iframe_element:
          # Извлекаем ссылку из атрибута src
          youtube_link_str = iframe_element['src']
     elif youtube_link_element:
          # Если iframe не найден, но элемент video_block существует, используем его текст
          youtube_link_str = youtube_link_element.text.strip()
     else:
          youtube_link_str = 'No info'

     return youtube_link_str



def extract_article_number(another_soup):
    article_element = another_soup.find('span', class_='block_title')
    article_value = None

    if article_element:
        value_element = article_element.find_next_sibling('span', class_='value')
        if value_element:
            article_value = value_element.get_text(strip=True)

    if article_value:
        atricle_value_str = f"Артикул: '{article_value}'"
    else:
        atricle_value_str = 'No info'

    return atricle_value_str


def extract_download_link(vkusno):
    link_element = vkusno.find('a', string='Скачать КП')

    if link_element and link_element.has_attr('href'):
        return f'https://krasmehanika.ru{link_element["href"]}'

    return 'No info'


counter = 0
for item in a:
    product_response = requests.get(item)
    product_soup = BeautifulSoup(product_response.text, 'lxml')

    product_name = product_soup.find('h1', id='pagetitle').text
    product_description = extract_and_format_text(product_soup.find('div', class_='detail_text'))
    product_characteristics = extract_characteristics(product_soup)
    product_price = extract_price(product_soup)
    product_availability = extract_availability(product_soup)
    product_article = extract_article_number(product_soup)
    kp_link = extract_download_link(product_soup)
    youtube_link = extract_youtube_link(product_soup)

    products_df.loc[len(products_df)] = [item, product_name, product_description, product_characteristics,
                                         product_price, product_availability, product_article, kp_link, youtube_link]
    counter += 1
    print(counter)

products_df.to_excel('products.xlsx', index=False)
